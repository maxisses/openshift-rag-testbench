{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a331fd6",
   "metadata": {},
   "source": [
    "## RAG example with Langchain, Milvus, and vLLM\n",
    "\n",
    "Requirements:\n",
    "- A Milvus instance, either standalone or cluster.\n",
    "- Connection credentials to Milvus must be available as environment variables: MILVUS_USERNAME and MILVUS_PASSWORD.\n",
    "- A vLLM inference endpoint. In this example we use the OpenAI Compatible API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e712b3e8-f406-4387-9188-3e2f20a6841f",
   "metadata": {},
   "source": [
    "### Needed packages and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d4a359bd-4f69-4e88-82c0-5763c26aa0af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E0423 09:43:34.977219108    1844 completion_queue.cc:746]              Kick failed: UNKNOWN:Bad file descriptor {created_time:\"2024-04-23T09:43:34.977068592+00:00\", errno:9, os_error:\"Bad file descriptor\", syscall:\"eventfd_write\"}\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q einops==0.7.0 langchain==0.1.9 pymilvus==2.3.6 sentence-transformers==2.4.0 openai==1.13.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "83e11d23-c0ad-4875-b67f-149fc8b14725",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.callbacks import StdOutCallbackHandler\n",
    "from langchain_community.llms import VLLMOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.vectorstores import Milvus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd4537b",
   "metadata": {},
   "source": [
    "#### Bases parameters, Inference server and Milvus info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "98401d00-bcc5-4267-8af1-04d8e9cde647",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"EMPTY\"\n",
    "OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "51baf1a6-4111-4b40-b43a-833438bdc222",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replace values according to your Milvus deployment\n",
    "\n",
    "### local / in-cluster\n",
    "# INFERENCE_SERVER_URL = \"http://vllm.rag-with-llama2-model-deployment.svc.cluster.local:8000/v1\"\n",
    "\n",
    "### ocp route\n",
    "INFERENCE_SERVER_URL =\"http://vllm:8000/v1\"\n",
    "MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "MAX_TOKENS=2048\n",
    "TOP_P=0.95\n",
    "TEMPERATURE=0.01\n",
    "PRESENCE_PENALTY=1.03\n",
    "MILVUS_HOST = \"vectordb-milvus\"\n",
    "MILVUS_PORT = 19530\n",
    "MILVUS_USERNAME = \"root\"\n",
    "MILVUS_PASSWORD = \"Milvus\"\n",
    "MILVUS_COLLECTION = \"redhat_notes\"\n",
    "RAG_NEAREST_NEIGHBOURS = \"5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4c1b1a",
   "metadata": {},
   "source": [
    "#### Initialize the connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bbb6a3e3-5ccd-441e-b80d-427555d9e9f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You try to use a model that was created with version 2.4.0.dev0, however, your version is 2.4.0. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
      "\n",
      "\n",
      "\n",
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "model_kwargs = {'trust_remote_code': True}\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"nomic-ai/nomic-embed-text-v1\",\n",
    "    model_kwargs=model_kwargs,\n",
    "    show_progress=False\n",
    ")\n",
    "\n",
    "store = Milvus(\n",
    "    embedding_function=embeddings,\n",
    "    connection_args={\"host\": MILVUS_HOST, \"port\": MILVUS_PORT, \"user\": MILVUS_USERNAME, \"password\": MILVUS_PASSWORD},\n",
    "    collection_name=MILVUS_COLLECTION,\n",
    "    metadata_field=\"metadata\",\n",
    "    text_field=\"page_content\",\n",
    "    drop_old=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72a3a2b",
   "metadata": {},
   "source": [
    "#### Initialize query chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7948603a-2c64-4bff-8ef2-161737c96157",
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"\"\"<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant named SnemeisBot answering questions.\n",
    "You will be given a question you need to answer, and a context about everything a sales team wrote down about its customers to provide you with information. You must answer the question based as much as possible on this context.\n",
    "\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, don't share false information.\n",
    "<</SYS>>\n",
    "\n",
    "Context: \n",
    "{context}\n",
    "\n",
    "Question: {question} [/INST]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7892e37",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ed8fd396-0798-45c5-8969-6b6ede134c77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"\"\"<s>[INST] <<SYS>>\n",
    "            You are a helpful, respectful and honest assistant named SnemeisBot. You are answering a question.\n",
    "            You will be given a question you need to answer, and a context about everything a sales team wrote down about its customers to provide you with information. You must answer the question based as much as possible on this context.\n",
    "\n",
    "            If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, don't share false information.\n",
    "            <</SYS>>\n",
    "            \n",
    "            Use the following context (delimited by <ctx></ctx>) and the chat history (delimited by <hs></hs>) to answer the question in a helpful, respectful manner:\n",
    "            ------\n",
    "            <ctx>\n",
    "            {context}\n",
    "            </ctx>\n",
    "            ------\n",
    "            <hs>\n",
    "            {history}\n",
    "            </hs>\n",
    "            ------\n",
    "            {question}\n",
    "            Answer:\n",
    "            \"\"\"\n",
    "\n",
    "# QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
    "prompt_template = PromptTemplate(\n",
    "        input_variables=[\"history\", \"context\", \"question\"],\n",
    "        template=template,\n",
    "    )\n",
    "\n",
    "llm = VLLMOpenAI(\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    openai_api_base=INFERENCE_SERVER_URL,\n",
    "    model_name=MODEL_NAME,\n",
    "    max_tokens=MAX_TOKENS,\n",
    "    top_p=TOP_P,\n",
    "    temperature=TEMPERATURE,\n",
    "    presence_penalty=PRESENCE_PENALTY,\n",
    "    streaming=True,\n",
    "    verbose=False,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "\n",
    "handler = StdOutCallbackHandler()\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm,\n",
    "        retriever=store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": int(RAG_NEAREST_NEIGHBOURS)}),\n",
    "        chain_type_kwargs={\n",
    "            \"prompt\": prompt_template, \n",
    "            \"verbose\": True,\n",
    "            \"memory\": ConversationBufferMemory(\n",
    "                memory_key=\"history\",\n",
    "                input_key=\"question\"),},\n",
    "        return_source_documents=True\n",
    "    )\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a45ad23",
   "metadata": {},
   "source": [
    "#### Query example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "105d2fd1-f36c-409d-8e52-ec6d23a56ad1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m<s>[INST] <<SYS>>\n",
      "            You are a helpful, respectful and honest assistant named SnemeisBot. You are answering a question.\n",
      "            You will be given a question you need to answer, and a context about everything a sales team wrote down about its customers to provide you with information. You must answer the question based as much as possible on this context.\n",
      "\n",
      "            If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, don't share false information.\n",
      "            <</SYS>>\n",
      "            \n",
      "            Use the following context (delimited by <ctx></ctx>) and the chat history (delimited by <hs></hs>) to answer the question in a helpful, respectful manner:\n",
      "            ------\n",
      "            <ctx>\n",
      "            Interesting people who speak to the customer.\n",
      "\n",
      "Are changes are interesting\n",
      "\n",
      "Product Manager:Stefan Banok? now with Mendix: wil send contacts in Modular MOM - they have no clue about such a solution . guilano will tell us who is that\n",
      "\n",
      "Architects do not think like a customer\n",
      "\n",
      "Next call - also with Manager with Red Hat\n",
      "\n",
      "He has less power to decide technology - he can help to influence Produkt Manager\n",
      "\n",
      "May be start with Dan and one of the Product Manager - may be they have a customer in mind\n",
      "\n",
      "In touch\n",
      "\n",
      "Customer Reference SPIFF Nomination\t\t       => Win Wire/Customer Story on The Source\n",
      "\n",
      "\n",
      "\n",
      "Key topic: New solutions or add-ons to OpenShift , Industrial Edge\n",
      "\n",
      "\n",
      "\n",
      "Company Name *\n",
      "\n",
      "\n",
      "\n",
      "Siemens AG, Digital Industries, Amberg, Germany\n",
      "\n",
      "\n",
      "\n",
      "Customer Contact - who would be the best spokesperson for the reference?\n",
      "\n",
      "Christian Schulze, christian.schulze@siemens.com, IT project manager\n",
      "\n",
      "Stephan Bernt, stephan.bernt@siemens.com, IT Communication/PR contact (to be checked)\n",
      "\n",
      "\n",
      "\n",
      "Brief description of the customer's story\n",
      "\n",
      "Siemens Digital Industries is creating solutions used at the industrial shop floor, e.g. manufacturing execution systems, order management software, etc.\n",
      "\n",
      "These solutions are critical to operations - if a machine can't get the details of the next order to execute, production can grind to an expensive hold.\n",
      "\n",
      "\n",
      "\n",
      "Challenge: \n",
      "\n",
      "Siemens Amberg, one of the most modern of 123 Siemens factories producing 17 million PLC´s per year, had an old, monolith application/architecture with poor documentation.\n",
      "\n",
      "\n",
      "\n",
      "Solution: \n",
      "\n",
      "Migrate infrastructure to a modern, cloud-ready and microservices-based modular enterprise architecture/ modern applications based on Red Hat OpenShift Container Platform at the factory site (industrial edge). The solution is in production since the end of November.\n",
      "\n",
      "\n",
      "\n",
      "Modern Application Architectures and Platforms help to provide more resilient applications while increasing the speed and agility of new features and functions.\n",
      "\n",
      "\n",
      "\n",
      "As a next step, Siemens is planning to add additional applications on the container platform. Starting with the Order Management Siemens is planning to run a new MES (Manufacturing Execution System) and also a communication platform on the horizontal layer. Siemens is not only planning to run additional workload on the platform but also run out these applications to other factories like Fürth or China.\n",
      "\n",
      "\n",
      "\n",
      "Which Red Hat products is the customer using in production? Please include versions where applicable.\n",
      "\n",
      "Red Hat OpenShift Container Platform \n",
      "\n",
      "Red Hat Consulting\n",
      "\n",
      "They are managed services provider for Siemens\n",
      "\n",
      "Manages some of their applications, including Energy/Spectrum\n",
      "\n",
      "They don’t engage, but they just process a PO (Thomas Connor is the rep)\n",
      "\n",
      "Separate pricebook and order form for processing as well\n",
      "\n",
      "Questions\n",
      "\n",
      "Does the client have in house skills to manage/scale this?\n",
      "\n",
      "They have their own sales team, consulting teams, and software team\n",
      "\n",
      "Eventually they’ll take control of how they do customer implementations, but initially they’ll need help from us we expect\n",
      "\n",
      "Using cloud or on prem now? (ROSA/ARO)\n",
      "\n",
      "All based on client need, so it could be either one\n",
      "\n",
      "Execs that oversee this initiative?\n",
      "\n",
      "Tobias owns this, will share\n",
      "\n",
      "Raymond Cock (sits as chair over this, and sold on the OCP)\n",
      "\n",
      "Dave Mitchell (sales director for this solution)\n",
      "\n",
      "Kevin Zone and Larry will synch up\n",
      "\n",
      " siemens-account-team@redhat.com\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "01/13/21 Tobias\n",
      "\n",
      "Mountain biking, loves it\n",
      "\n",
      "Wife\n",
      "\n",
      "Kids are 21, 18, 16, and 13\n",
      "\n",
      "2 were foriegn exchange students\n",
      "\n",
      "Stayed with mormon families in Arizona\n",
      "\n",
      "Decentralized\n",
      "\n",
      "Healthcare, energy, transportation, etc.\n",
      "\n",
      "Teams are spread globally (US, Italy, Germany, India)\n",
      "\n",
      "$8 M Euros annual spend (US contributes majorly to that)\n",
      "\n",
      "He covers Abbott account also, but will be dropping it\n",
      "\n",
      "iSV business will be key here\n",
      "\n",
      "Siemens could be #1\n",
      "\n",
      "Embedding our software into ISV he means (not hyperscalers)\n",
      "\n",
      "Mindsphere to close this month he think\n",
      "\n",
      "Will only close when Siemens sells the product\n",
      "\n",
      "ISV account manager (Anke), very smart and good\n",
      "\n",
      "In Germany, struggling with SA’s\n",
      "\n",
      "10 years of 14 at Red Hat covering Siemens\n",
      "\n",
      "Whoever calls him gets attention\n",
      "\n",
      "Doesn’t want too many people on the calls unnecessarily\n",
      "\n",
      "IBM not very strong in this account, and complicated\n",
      "\n",
      "They had bi-weekly cadence calls on Monday\n",
      "\n",
      "We have a TAM for Openshift (based in Germany)\n",
      "\n",
      "He’s struggling\n",
      "\n",
      "Team (V) Center and MOM?\n",
      "\n",
      "Other applications and stakeholders in and out of the USA\n",
      "\n",
      "\n",
      "\n",
      "He is 6 hours ahead of ET\n",
      "\n",
      "Starts at 7:30am until 6:30pm his time\n",
      "\n",
      "\n",
      "\n",
      "GAM rules\n",
      "\n",
      "Some ISV in Germany, end users in USA, but we see no revenue\n",
      "\n",
      "CUSTOMER: Siemens\n",
      "\n",
      "INDUSTRY: Technology\n",
      "\n",
      "PARTNER: N/A\n",
      "\n",
      "USE CASE: Orchestration, Configuration Management, Compliance and Security\n",
      "\n",
      "INTEGRATION: AWS/Azure\n",
      "\n",
      "BUSINESS ISSUE: Self-service cloud provisioning and configuration management\n",
      "\n",
      "BUSINESS CHALLENGE:\n",
      "\n",
      "Siemens is a global manufacturing powerhouse, with over 370,000 employees worldwide. Its many business units are serviced by a central IT function – Global Services IT (GSIT). While GSIT provides services, such as public and private cloud, it cannot enforce policies and set standards across business units and departments. Furthermore, with a target to move 50% of Siemens’ workload to the cloud (AWS and Azure), internal customers were constrained by the weeks and months needed to order cloud accounts. To address these challenges, Siemens needed a self-service solution that would automate and speed cloud provisioning while enforcing consistent environments across its operations.\n",
      "\n",
      "SOLUTION:\n",
      "\n",
      "Ansible Tower provides a powerful self-service tool and automation framework for implementing a consistent infrastructure that speeds cloud service deployment and time to market, while driving the complexity out of configuration management. \n",
      "\n",
      "With Tower, orchestrating the most complex tasks becomes merely the click of a button even for the non-technical people in your organization. New team members can quickly dive in and make an impact.\n",
      "\n",
      "RESULTS:\n",
      "\n",
      "With 1,000 Tower licenses allocated as needed, GSIT’s internal customers can now order cloud services in a matter of minutes, not weeks or months. IT on-demand also extends to configuration management. Customers can spin-up Tower in their own cloud environment to ensure that every server is properly configured, automatically. The result is complete automated control of hardening and patching to Siemens’ business units, freeing up GSIT to attend to more critical and strategic work instead of configuration management.\n",
      "\n",
      "Using Tower as a central customer-facing portal, Ansible has provided the following benefits:\n",
      "\n",
      "Sustainability \n",
      "\n",
      "Tobias to callNorbert Schlegl\n",
      "\n",
      "Beitinger comment\n",
      "\n",
      "Event?\n",
      "\n",
      "Amy : how could the event look like - draft\n",
      "\n",
      "General question: who is driving the McKinsey relationship?\n",
      "            </ctx>\n",
      "            ------\n",
      "            <hs>\n",
      "            Human: What do you know about Max Dargatz?\n",
      "AI: \n",
      "            Max Dargatz is a person mentioned in the context who has been speaking with a potential customer about Linux and their industrial operating system. He mentions that they have their own Debian-based industrial OS, but the responsible person for it is not present during their meetings. The customer sells over 100,000 IPCs per year, with 80% being Windows-based. They have previously considered using Linux but found there wasn't enough demand at that time. Max also mentions that the customer's approach to application lifecycle management is proprietary and they have handmade scripting for automation. He proposes shifting to a more open approach using Kubernetes and leveraging the open source community. Additionally, he mentions that the customer is interested in AI and machine learning, and they have an offering in that area but it is proprietary. Max also mentions that they are transforming into a software company and have an Industrial Edge portfolio focusing on managing edge devices and applications.\n",
      "            </hs>\n",
      "            ------\n",
      "            In that context - who is the customer?\n",
      "            Answer:\n",
      "            \u001b[0m\n",
      "\n",
      "            Siemens AG, Digital Industries, Amberg, Germany\n",
      "            \n",
      "            Based on the context provided, Max Dargatz is discussing with a representative from Siemens AG about potential solutions for their industrial operating system. Therefore, Siemens AG is the customer in this scenario.\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "question = \"In that context - who is the customer?\"\n",
    "result = qa_chain.invoke({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f9556720-25e3-4f9e-aecf-61cee0287c61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'In that context - who is the customer?',\n",
       " 'result': '\\n            Siemens AG, Digital Industries, Amberg, Germany\\n            \\n            Based on the context provided, Max Dargatz is discussing with a representative from Siemens AG about potential solutions for their industrial operating system. Therefore, Siemens AG is the customer in this scenario.',\n",
       " 'source_documents': [Document(page_content='Interesting people who speak to the customer.\\n\\nAre changes are interesting\\n\\nProduct Manager:Stefan Banok? now with Mendix: wil send contacts in Modular MOM - they have no clue about such a solution . guilano will tell us who is that\\n\\nArchitects do not think like a customer\\n\\nNext call - also with Manager with Red Hat\\n\\nHe has less power to decide technology - he can help to influence Produkt Manager\\n\\nMay be start with Dan and one of the Product Manager - may be they have a customer in mind\\n\\nIn touch', metadata={'source': './snemeis-docx/Siemens Digital Industrie MOM OpenShift.docx'}),\n",
       "  Document(page_content=\"Customer Reference SPIFF Nomination\\t\\t       => Win Wire/Customer Story on The Source\\n\\n\\n\\nKey topic: New solutions or add-ons to OpenShift , Industrial Edge\\n\\n\\n\\nCompany Name *\\n\\n\\n\\nSiemens AG, Digital Industries, Amberg, Germany\\n\\n\\n\\nCustomer Contact - who would be the best spokesperson for the reference?\\n\\nChristian Schulze, christian.schulze@siemens.com, IT project manager\\n\\nStephan Bernt, stephan.bernt@siemens.com, IT Communication/PR contact (to be checked)\\n\\n\\n\\nBrief description of the customer's story\\n\\nSiemens Digital Industries is creating solutions used at the industrial shop floor, e.g. manufacturing execution systems, order management software, etc.\\n\\nThese solutions are critical to operations - if a machine can't get the details of the next order to execute, production can grind to an expensive hold.\\n\\n\\n\\nChallenge: \\n\\nSiemens Amberg, one of the most modern of 123 Siemens factories producing 17 million PLC´s per year, had an old, monolith application/architecture with poor documentation.\\n\\n\\n\\nSolution: \\n\\nMigrate infrastructure to a modern, cloud-ready and microservices-based modular enterprise architecture/ modern applications based on Red Hat OpenShift Container Platform at the factory site (industrial edge). The solution is in production since the end of November.\\n\\n\\n\\nModern Application Architectures and Platforms help to provide more resilient applications while increasing the speed and agility of new features and functions.\\n\\n\\n\\nAs a next step, Siemens is planning to add additional applications on the container platform. Starting with the Order Management Siemens is planning to run a new MES (Manufacturing Execution System) and also a communication platform on the horizontal layer. Siemens is not only planning to run additional workload on the platform but also run out these applications to other factories like Fürth or China.\\n\\n\\n\\nWhich Red Hat products is the customer using in production? Please include versions where applicable.\\n\\nRed Hat OpenShift Container Platform \\n\\nRed Hat Consulting\", metadata={'source': './snemeis-docx/Customer Reference_Siemens Amberg.docx'}),\n",
       "  Document(page_content='They are managed services provider for Siemens\\n\\nManages some of their applications, including Energy/Spectrum\\n\\nThey don’t engage, but they just process a PO (Thomas Connor is the rep)\\n\\nSeparate pricebook and order form for processing as well\\n\\nQuestions\\n\\nDoes the client have in house skills to manage/scale this?\\n\\nThey have their own sales team, consulting teams, and software team\\n\\nEventually they’ll take control of how they do customer implementations, but initially they’ll need help from us we expect\\n\\nUsing cloud or on prem now? (ROSA/ARO)\\n\\nAll based on client need, so it could be either one\\n\\nExecs that oversee this initiative?\\n\\nTobias owns this, will share\\n\\nRaymond Cock (sits as chair over this, and sold on the OCP)\\n\\nDave Mitchell (sales director for this solution)\\n\\nKevin Zone and Larry will synch up\\n\\n siemens-account-team@redhat.com\\n\\n\\n\\n\\n\\n01/13/21 Tobias\\n\\nMountain biking, loves it\\n\\nWife\\n\\nKids are 21, 18, 16, and 13\\n\\n2 were foriegn exchange students\\n\\nStayed with mormon families in Arizona\\n\\nDecentralized\\n\\nHealthcare, energy, transportation, etc.\\n\\nTeams are spread globally (US, Italy, Germany, India)\\n\\n$8 M Euros annual spend (US contributes majorly to that)\\n\\nHe covers Abbott account also, but will be dropping it\\n\\niSV business will be key here\\n\\nSiemens could be #1\\n\\nEmbedding our software into ISV he means (not hyperscalers)\\n\\nMindsphere to close this month he think\\n\\nWill only close when Siemens sells the product\\n\\nISV account manager (Anke), very smart and good\\n\\nIn Germany, struggling with SA’s\\n\\n10 years of 14 at Red Hat covering Siemens\\n\\nWhoever calls him gets attention\\n\\nDoesn’t want too many people on the calls unnecessarily\\n\\nIBM not very strong in this account, and complicated\\n\\nThey had bi-weekly cadence calls on Monday\\n\\nWe have a TAM for Openshift (based in Germany)\\n\\nHe’s struggling\\n\\nTeam (V) Center and MOM?\\n\\nOther applications and stakeholders in and out of the USA\\n\\n\\n\\nHe is 6 hours ahead of ET\\n\\nStarts at 7:30am until 6:30pm his time\\n\\n\\n\\nGAM rules\\n\\nSome ISV in Germany, end users in USA, but we see no revenue', metadata={'source': './snemeis-docx/Siemens.docx'}),\n",
       "  Document(page_content='CUSTOMER: Siemens\\n\\nINDUSTRY: Technology\\n\\nPARTNER: N/A\\n\\nUSE CASE: Orchestration, Configuration Management, Compliance and Security\\n\\nINTEGRATION: AWS/Azure\\n\\nBUSINESS ISSUE: Self-service cloud provisioning and configuration management\\n\\nBUSINESS CHALLENGE:\\n\\nSiemens is a global manufacturing powerhouse, with over 370,000 employees worldwide. Its many business units are serviced by a central IT function – Global Services IT (GSIT). While GSIT provides services, such as public and private cloud, it cannot enforce policies and set standards across business units and departments. Furthermore, with a target to move 50% of Siemens’ workload to the cloud (AWS and Azure), internal customers were constrained by the weeks and months needed to order cloud accounts. To address these challenges, Siemens needed a self-service solution that would automate and speed cloud provisioning while enforcing consistent environments across its operations.\\n\\nSOLUTION:\\n\\nAnsible Tower provides a powerful self-service tool and automation framework for implementing a consistent infrastructure that speeds cloud service deployment and time to market, while driving the complexity out of configuration management. \\n\\nWith Tower, orchestrating the most complex tasks becomes merely the click of a button even for the non-technical people in your organization. New team members can quickly dive in and make an impact.\\n\\nRESULTS:\\n\\nWith 1,000 Tower licenses allocated as needed, GSIT’s internal customers can now order cloud services in a matter of minutes, not weeks or months. IT on-demand also extends to configuration management. Customers can spin-up Tower in their own cloud environment to ensure that every server is properly configured, automatically. The result is complete automated control of hardening and patching to Siemens’ business units, freeing up GSIT to attend to more critical and strategic work instead of configuration management.\\n\\nUsing Tower as a central customer-facing portal, Ansible has provided the following benefits:', metadata={'source': './snemeis-docx/Kopie von Siemens Case Study V1.docx 2.docx'}),\n",
       "  Document(page_content='Sustainability \\n\\nTobias to callNorbert Schlegl\\n\\nBeitinger comment\\n\\nEvent?\\n\\nAmy : how could the event look like - draft\\n\\nGeneral question: who is driving the McKinsey relationship?', metadata={'source': './snemeis-docx/Siemens Sustainability.docx'})]}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d75d0c",
   "metadata": {},
   "source": [
    "#### Retrieve source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acda357e-558a-4879-8ad8-21f0567f2f2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_duplicates(input_list):\n",
    "    unique_list_doctitle = []\n",
    "    unique_list_doccontent = []\n",
    "    for item in input_list:\n",
    "        if item.metadata['source'] not in unique_list_doctitle:\n",
    "            unique_list_doctitle.append(item.metadata['source'])\n",
    "            unique_list_doccontent.append(item.page_content)\n",
    "    return unique_list_doctitle, unique_list_doccontent\n",
    "\n",
    "results = remove_duplicates(result['source_documents'])\n",
    "\n",
    "for s in results:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00f0f15-0491-41d5-87e4-974bad943dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(input_list):\n",
    "    unique_list = []\n",
    "    for item in input_list:\n",
    "        if item not in unique_list:\n",
    "            print(item.page_content)\n",
    "            unique_list.append(item.metadata['source'])\n",
    "    return unique_list\n",
    "\n",
    "results = remove_duplicates(result['source_documents'])\n",
    "\n",
    "for s in results:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7720bbea-d228-4211-8144-8286934ff70b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
